{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FPEF_practice_and_visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNH5KgW+7yOQo05LCH2+YqV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimGuenTaek/Object_Detection/blob/master/FPEF_practice_and_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT14kczswBPP"
      },
      "source": [
        "# 여기 cell 에서 image 하나 받아오고 , feature map 뽑아본뒤 visualization 해보고 기존 Feature 와 fused Feature 비교 해보기\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "feat4_3=torch.rand(1,512,38,38)\n",
        "feat7=torch.rand(1,1024,19,19)\n",
        "feat8_2=torch.rand(1,512,10,10)\n",
        "feat9_2=torch.rand(1,256,5,5)\n",
        "feat10_2=torch.rand(1,256,3,3)\n",
        "feat11_2=torch.rand(1,256,1,1)\n",
        "\n",
        "conv4_3_1=nn.Conv2d(512,256,1,stride=1)\n",
        "conv4_3_3=nn.Conv2d(512,512,3,stride=1,padding=1)\n",
        "\n",
        "conv7_1=nn.Conv2d(1024,256,1,stride=1)\n",
        "conv7_3=nn.Conv2d(512,1024,3,stride=1,padding=1)\n",
        "\n",
        "conv8_2_1=nn.Conv2d(512,256,1,stride=1)\n",
        "conv8_2_3=nn.Conv2d(512,512,3,stride=1,padding=1)\n",
        "\n",
        "conv9_2_1=nn.Conv2d(256,256,1,stride=1)\n",
        "conv9_2_3=nn.Conv2d(512,256,3,stride=1,padding=1)\n",
        "\n",
        "conv10_2_1=nn.Conv2d(256,256,1,stride=1)\n",
        "conv10_2_3=nn.Conv2d(512,256,3,stride=1,padding=1)\n",
        "\n",
        "Up7=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "Up8_2=nn.Upsample(scale_factor=1.9,mode=\"nearest\")\n",
        "Up9_2=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "Up10_2=nn.Upsample(scale_factor=5/3,mode=\"nearest\")\n",
        "Up11_2=nn.Upsample(scale_factor=3,mode=\"nearest\")\n",
        "\n",
        "# First step : applying 1 by 1 Conv for same channel 256\n",
        "feat4_3_1=conv4_3_1(feat4_3)\n",
        "feat7_1=conv7_1(feat7)\n",
        "feat8_2_1=conv8_2_1(feat8_2)\n",
        "feat9_2_1=conv9_2_1(feat9_2)\n",
        "feat10_2_1=conv10_2_1(feat10_2)\n",
        "feat11_2_1=feat11_2\n",
        "\n",
        "# Second step : Upsampling before first fusion\n",
        "\n",
        "Up_feat7=Up7(feat7_1)\n",
        "Up_feat8_2=Up8_2(feat8_2_1)\n",
        "Up_feat9_2=Up9_2(feat9_2_1)\n",
        "Up_feat10_2=Up10_2(feat10_2_1)\n",
        "Up_feat11_2=Up11_2(feat11_2_1)\n",
        "\n",
        "# Third step : first fusion , element wise addition\n",
        "\n",
        "fused_feat4_3=feat4_3_1+Up_feat7\n",
        "fused_feat7=feat7_1+Up_feat8_2\n",
        "fused_feat8_2=feat8_2_1+Up_feat9_2\n",
        "fused_feat9_2=feat9_2_1+Up_feat10_2\n",
        "fused_feat10_2=feat10_2_1+Up_feat11_2\n",
        "\n",
        "# Forth step : second fusion , torch.cat(,dim=1) + conv2d(512,N,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "feat4_3=conv4_3_3(torch.cat([feat4_3_1,fused_feat4_3],dim=1))\n",
        "feat7=conv7_3(torch.cat([feat7_1,fused_feat7],dim=1))\n",
        "feat8_2=conv8_2_3(torch.cat([feat8_2_1,fused_feat8_2],dim=1))\n",
        "feat9_2=conv9_2_3(torch.cat([feat9_2_1,fused_feat9_2],dim=1))\n",
        "feat10_2=conv10_2_3(torch.cat([feat10_2_1,fused_feat10_2],dim=1))\n",
        "\n",
        "# And now return the feature to the prediction layer\n",
        "print(feat4_3.shape) \n",
        "print(feat7.shape)   \n",
        "print(feat8_2.shape)\n",
        "print(feat9_2.shape)\n",
        "print(feat10_2.shape)\n",
        "print(feat11_2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}