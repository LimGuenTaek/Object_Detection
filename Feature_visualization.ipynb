{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1uX73-FDdHn07ds0c3y4rUqUcqghx_mSJ",
      "authorship_tag": "ABX9TyMbuOuikAyyHy7aai+JH3fm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimGuenTaek/Object_Detection/blob/master/Feature_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT14kczswBPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c67b189-842f-44f4-81fb-8e0ceaeb879e"
      },
      "source": [
        "%cd drive/MyDrive/SSD_tutorial/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/SSD_tutorial\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqTo7JCwofPR"
      },
      "source": [
        "# Feature_Map Visualization\n",
        "\n",
        "* checkpoint에 학습된 model이 담겨있는 checkpoint 건내주기\n",
        "* 이미지는 PIL class로 받아오고(비교를 위해 , 성능이 차이가 났던 이미지를 사용하는게 좋을 것이라 생각이 듬)\n",
        "* Feature_Map 저장을 어떻게 할지 고민중... 이름이 index로 저장해주니깐 헷갈림\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6S5_yrqrij"
      },
      "source": [
        "import torch\n",
        "from utils import *\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "checkpoint = '/content/drive/MyDrive/SSD_tutorial/tar/SSD(2007+2012).tar'\n",
        "checkpoint = torch.load(checkpoint)\n",
        "model = checkpoint['model']\n",
        "model = model.to(device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRdfT0oHiTh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6863dc58-ad84-438d-9bdd-4f261b440ee5"
      },
      "source": [
        "import torchvision.transforms.functional as FT\n",
        "image = Image.open('/content/drive/MyDrive/sample.jpg', mode='r') \n",
        "image = image.convert('RGB')\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "dims=(300, 300)\n",
        "\n",
        "new_image = FT.resize(image, dims)\n",
        "\n",
        "new_image = FT.to_tensor(new_image)\n",
        "\n",
        "new_image = FT.normalize(new_image, mean=mean, std=std)\n",
        "\n",
        "image=[]\n",
        "image.append(new_image)\n",
        "image=torch.stack(image,dim=0)\n",
        "print(image.shape) # Tensor로 변환 성공 "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 300, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Vg2ON-s8oQ"
      },
      "source": [
        "* 이제 checkpoint로 train된 model을 불러와서 이미지 넣어주고 feature_map을 반환 받고 \n",
        "\n",
        "* matplotlib로 visualization 행해주면 끝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VXrVjYirbXJ"
      },
      "source": [
        "model.eval()\r\n",
        "image=image.to(device)\r\n",
        "\r\n",
        "layer=[]\r\n",
        "layer.append(model.base.conv1_1)\r\n",
        "layer.append(model.base.conv1_2) \r\n",
        "layer.append(model.base.pool1)\r\n",
        "layer.append(model.base.conv2_1)\r\n",
        "layer.append(model.base.conv2_2) \r\n",
        "layer.append(model.base.pool2)\r\n",
        "layer.append(model.base.conv3_1)\r\n",
        "layer.append(model.base.conv3_2)\r\n",
        "layer.append(model.base.conv3_3) \r\n",
        "layer.append(model.base.pool3)\r\n",
        "layer.append(model.base.conv4_1)\r\n",
        "layer.append(model.base.conv4_2)\r\n",
        "layer.append(model.base.conv4_3) \r\n",
        "layer.append(model.base.pool4)\r\n",
        "layer.append(model.base.conv5_1)\r\n",
        "layer.append(model.base.conv5_2)\r\n",
        "layer.append(model.base.conv5_3) \r\n",
        "layer.append(model.base.pool5)\r\n",
        "layer.append(model.base.conv6)\r\n",
        "layer.append(model.base.conv7)\r\n",
        "layer.append(model.aux_convs.conv8_1)\r\n",
        "layer.append(model.aux_convs.conv8_2)\r\n",
        "layer.append(model.aux_convs.conv9_1)\r\n",
        "layer.append(model.aux_convs.conv9_2)\r\n",
        "layer.append(model.aux_convs.conv10_1)\r\n",
        "layer.append(model.aux_convs.conv10_2)\r\n",
        "layer.append(model.aux_convs.conv11_1)\r\n",
        "layer.append(model.aux_convs.conv11_2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwWob-mw5mtE"
      },
      "source": [
        "# Feature-Map Extraction\n",
        "\n",
        "* 우선 두 model에 대해 11개의 feature는 동일하게 뽑아보고 ,\n",
        "\n",
        "* Fused 된 feature들 6개 또한 따로 뽑아본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgEXkoLn55vZ"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "feature=[]\n",
        "out=layer[0](image)\n",
        "feature.append(out.to('cpu'))\n",
        "\n",
        "for i in range(1,len(layer)):\n",
        "  out=layer[i](out)\n",
        "  if isinstance(layer[i],nn.Conv2d):\n",
        "    feature.append(out.to('cpu'))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFq8gUs-cPxU"
      },
      "source": [
        "import matplotlib.pyplot as plt # to display and save the filters and feature map images\n",
        "\n",
        "# visualize 64 features from each layer , although there are more feature maps in the upper layers\n",
        "for num_layer in range(len(feature)):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    layer_viz = feature[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    print(layer_viz.size())\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "        if i == 1: # we will visualize only 8x8 blocks from each layer\n",
        "            break\n",
        "        plt.subplot(1, 1, i + 1)\n",
        "        plt.imshow(filter, cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    print(f\"Saving layer {num_layer} feature maps...\")\n",
        "    plt.savefig(f\"/content/drive/MyDrive/Feature_map/Original/{num_layer}.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}